# Common defaults for both binary and multiclass runs

data:
  preprocessed_dir: "data/preprocessed"
  val_split: 0.20
  test_split: 0.10

  # where raw audio lives
  raw_dir: "data/speech_commands_v0.02"

  # MFCC/feature extraction settings
  mfcc:
    sample_rate: 16000         # sr
    n_mfcc: 28
    frame_length_s: 0.032       # seconds
    hop_length_s: 0.016         # seconds
    fixed_duration_s: 1.024      # seconds (pad/truncate)

augmentation:
  enable: true               # turn off by setting false
  max_shift_ms: 100          # “up to 100 ms forward/backward shifts”
  noise_prob: 0.15           # 15% chance to add noise after the shift
  noise_std_factor: 0.05     # noise std = noise_std_factor * per-sample feature std
  seed: 0                    # optional; set null to get fully random every run

task:
  type: multiclass
  class_list: ["yes", "no", "up", "down", "stop", "go"]
  include_unknown: true
  include_background: false
  # Optional caps for training only
  unknown_max_ratio: null   # keep at most a portion of keyword samples
  unknown_max_count: null   # or an absolute cap (e.g., 5000); null to ignore

model:
  # Core
  hidden_channels: 22
  kernel_size: 2
  dropout: 0.2

  # Depth (number of residual TCN blocks with exponential dilation)
  num_blocks: 8

  # Convolutional block options
  causal: true                      # causal padding + right-trim
  activation: relu                  # relu | gelu | prelu
  norm: none                       # batch | group | layer | none
  groups_for_groupnorm: 8           # only used when norm=group
  use_weight_norm: false            # apply weight_norm to convs
  depthwise_separable: false       # use depthwise+pointwise convs
  pool: avg                         # avg | max (global pool over time)
  bias: false                        # include bias in conv layers
#
train:
  batch_size: 32
  num_epochs: 100
  learning_rate: 1.0e-4
  weight_decay: 1.0e-5
  device: auto               # "auto" | "cuda" | "cpu"

  # DataLoader performance knobs
  num_workers: 2             # >0 enables parallel loading (Windows-safe if main-guarded)
  pin_memory: true           # only helps when using CUDA
  persistent_workers: true   # keep workers alive across epochs (requires num_workers > 0)
  prefetch_factor: 2         # batches prefetched per worker

qat:
  # quant config
  weight_bits: 3
  act_bits: 5
  weight_symmetric: true
  act_symmetric: false

  # Use globally fixed scales after warmup (derive from data/observers)
  weight_use_global_scale: true
  act_use_global_scale: true
  warmup_epochs: 1

  # training hyperparams
  batch_size: 32
  num_epochs: 5
  learning_rate: 1.0e-5
  # Optional: override model.dropout during QAT
  dropout: 0.10

output:
  weights_dir: "checkpoints"
  plots_dir: "plots"
  tqdm: true




